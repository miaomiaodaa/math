**背景**  
 $K$ : 是数域  
 $V_K^n$ : 是数域 $K$ 上的 $n$ 维线性空间  
 $e_1,e_2,\cdots,e_n$ : 是 $V_K^n$ 的一个基  
 $\Phi$ : 是 $V_K^n$ 上的线性变换，即 $\Phi\in\mathbb{L}(V_K^n)$  
设 $\Phi$ 的表示矩阵为对角阵 $\rm{diag}(\lambda_1,\lambda_2,\cdots,\lambda_n)$  
则可以得出以下良好结论  
  
 $1^\circ\ (\ \Phi(e_1),\Phi(e_2),\cdots,\Phi(e_n)\ )=(e_1,e_2,\cdots,e_n)\cdot\begin{bmatrix}  
\lambda_1\\\  
&\lambda_2\\\  
&&\lambda_3\\\  
&&&\ddots\\\  
&&&&\lambda_n  
\end{bmatrix}$  
 $\Rightarrow\Phi(e_i)=\lambda_1\cdot e_i$  
  
 $2^\circ\ \forall\alpha\in V_K^n$  
 $\Rightarrow\Phi(\alpha)=\Phi(a_1e_1+\cdots+a_ne_n)=a_1\Phi(e_1)+\cdots+a_n\Phi(e_n)=a_1\lambda_1e_1+\cdots+a_n\lambda_ne_n$  
 $\Rightarrow\Phi(\alpha)=\sum\limits_{i=1}^na_i\lambda_ie_i$  
 $\alpha$ 对应的坐标向量 $(a_1,a_2,\cdots,a_n)$  
 $\Phi(\alpha)$ 对应的坐标向量 $(a_1\lambda_1,a_2\lambda_2,\cdots,a_n\lambda_n)$  
 $\Phi$ 的表示矩阵 $A$  
由表示矩阵与坐标向量的关系( $Y=AX$ )得  
 $A\cdot(a_1,a_2,\cdots,a_n)^T=(a_1\lambda_1,a_2\lambda_2,\cdots,a_n\lambda_n)^T$  
  
 $3^\circ\ $ 若 $\lambda_1,\lambda_2,\cdots,\lambda_r$ 非零， $\lambda_{r+1}=\lambda_{r+2}=\cdots=\lambda_n=0$  
 $\Rightarrow T(\Phi)=r$  
  
 $\Rightarrow\rm{dim}_K(\rm{Ker}(\Phi))=n-r$  
 $\Rightarrow\rm{Ker}(\Phi)=\rm{L}(e_{r+1},e_{r+2},\cdots,e_n)$  
  
 $\Rightarrow\rm{dim}_K(\rm{Im}(\Phi))=r$  
 $\Rightarrow\rm{Im}(\Phi)=\rm{L}(e_1,e_2,\cdots,e_r)$  
  
小结:  $\Phi(\alpha),\rm{r}(\Phi),\rm{Ker}(\Phi),\rm{Im}(\Phi)$ ，能把这些信息快速求得，关键点是 $\Phi(e_i)=\lambda_i\cdot e_i,\ 1\le i\le n$  
  
---  
  
分析 $\Phi(e_i)=\lambda_i\cdot e_i$  
 $\Rightarrow e_i\neq\mathbf0_V$  
所以抽象出特征值，特征向量的概念，但是特征向量有无穷个，**所以这无穷个里面是否总包含基向量呢**，若包含，则可以对角化，则可以拼成全空间的基，就可以直和分解了  
特征值与特征向量是1对无穷的关系  
  
---  
  
 $\begin{array}{l}  
\Phi的特征值\lambda_0的特征子空间&\leftrightarrow&\lambda_0 I_V-\Phi的核空间\\\  
\updownarrow&&\updownarrow\\\  
A的特征子空间&\leftrightarrow&齐次线性方程组(\lambda_0 I_n-A)x=\mathbf0_V的解空间  
\end{array}$  
