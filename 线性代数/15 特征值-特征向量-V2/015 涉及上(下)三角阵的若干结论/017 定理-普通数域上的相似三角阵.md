**内容**    
若数域 $K$ 上的 $n$ 阶方阵 $A$ ，在 $K$ 上存在 $n$ 个特征值，则在 $K$ 上存在与 $A$ 相似的三角阵    
    
若 $n$ 阶方阵 $A$ 在数域 $K$ 上存在 $n$ 个特征值，则在该域上存在与 $A$ 相似的三角阵    
    
设 $A\in M_n(K)$ ，有 $n$ 个特征值，且均在 $K$ 中，则存在可逆阵 $P\in M_n(K)$ ，使得 $\begin{bmatrix}    
\lambda_1&\cdots&\bigstar\\\     
&\ddots&\bigstar\\\     
&&\lambda_n    
\end{bmatrix}=P^{-1}\cdot A\cdot P$     
    
**说明**    
也能反过来看吧，先证明一般数域上的相似矩阵，再特殊到复数域    
    
**证明**    
数学归纳法，对阶数 $n$ 进行归纳    
 $n=1$ ，结论显然    
假设阶数小于 $n$ 时结论成立，下面证明 $n$ 的情形    
由条件知，可任取 $A$ 的一个特征值 $\alpha_1$     
 $\Rightarrow A\alpha_1=\lambda_1\alpha_1,\alpha_1\neq0$     
 $\Rightarrow\alpha_1$ 线性无关    
由基扩张定理知，可以将 $\alpha_1$ 扩张为 $K^n$ 的一个基 $(\alpha_1,\alpha_2,\cdots,\alpha_n)$     
令 $P=(\alpha_1,\alpha_2,\cdots,\alpha_n)$ ，则 $P\in M_n(K)$     
又因为 $(\alpha_1,\alpha_2,\cdots,\alpha_n)$ 线性无关    
 $\Rightarrow P$ 满秩，非奇异，可逆    
将 $A$ 与 $P$ 相乘得， $AP=(A\alpha_1,A\alpha_2,\cdots,A\alpha_n)$     
 $=(\alpha_1,\alpha_2,\cdots,\alpha_n)\cdot\begin{bmatrix}    
\lambda_1&\bigstar_{1\times n-1}\\\     
\mathbf{O}_{n-1\times1}&A_{n-1}    
\end{bmatrix},\ A_{n-1}\in M_{n-1}(K)$     
    
 $\Rightarrow AP=P\begin{bmatrix}\lambda_1&\bigstar_{1\times n-1}\\\ \mathbf{O}_{n-1\times1}&A_{n-1}\end{bmatrix}$     
    
 $\Rightarrow P^{-1}\cdot A\cdot P=\begin{bmatrix}\lambda_1&\bigstar_{1\times n-1}\\\ \mathbf{O}_{n-1\times1}&A_{n-1}\end{bmatrix}$     
    
 $\Rightarrow|\lambda E_n-A_n|    
=\begin{bmatrix}\lambda-\lambda_1&\bigstar_{1\times n-1}\\\ \mathbf{O}_{n-1\times1}&\lambda E_{n-1}-A_{n-1}\end{bmatrix}    
=(\lambda-\lambda_1)|\lambda E_{n-1}-A_{n-1}|$     
    
 $\Rightarrow A_{n-1}$ 的特征值有 $n-1$ 个，且都在 $K$ 中    
（等式左边有 $\lambda_1,\lambda_2,\cdots,\lambda_n\in K$ ，自然等式右边的所有特征值也在 $K$ 中）    
    
由归纳假设知，存在非异阵 $Q\in M_{n-1}(K)$ ，使得 $Q^{-1}A_{n-1}Q=\begin{bmatrix}    
\lambda_2&\cdots&\bigstar\\\    
&\ddots&\bigstar\\\    
&&\lambda_n    
\end{bmatrix}_{n-1}$     
    
令 $R=\begin{bmatrix}1&\mathbf{O}_{1\times n-1}\\\ \mathbf{O}_{n-1\times1}&Q\end{bmatrix}\in M_n(K)$ （由拉普拉斯展开，易知 $R$ 是非异阵）    
    
 $\Rightarrow R^{-1}\cdot(P^{-1}\cdot A\cdot P)\cdot R    
=R^{-1}\cdot\begin{bmatrix}\lambda_1&\bigstar_{1\times n-1}\\\ \mathbf{O}_{n-1\times1}&A_{n-1}\end{bmatrix}\cdot R$     
    
 $\Rightarrow (PR)^{-1}\cdot A\cdot(PR)    
=\begin{bmatrix}1&\mathbf{O}_{1\times n-1}\\\ \mathbf{O}_{n-1\times1}&Q^{-1}\end{bmatrix}    
\cdot\begin{bmatrix}\lambda_1&\bigstar_{1\times n-1}\\\ \mathbf{O}_{n-1\times1}&A_{n-1}\end{bmatrix}    
\cdot\begin{bmatrix}1&\mathbf{O}_{1\times n-1}\\\ \mathbf{O}_{n-1\times1}&Q\end{bmatrix}$     
    
 $=\begin{bmatrix}\lambda_1&\bigstar_{1\times n-1}\\\ \mathbf{O}_{n-1\times1}&Q^{-1}\cdot A_{n-1}\end{bmatrix}    
\cdot\begin{bmatrix}1&\mathbf{O}_{1\times n-1}\\\ \mathbf{O}_{n-1\times1}&Q\end{bmatrix}$     
    
 $=\begin{bmatrix}\lambda_1&\bigstar_{1\times n-1}\cdot Q\\\ \mathbf{O}_{n-1\times1}&Q^{-1}\cdot A_{n-1}\cdot Q\end{bmatrix}$     
    
 $=\begin{bmatrix}\lambda_1&\bigstar_{1\times n-1}\cdot Q\\\     
\mathbf{O}_{n-1\times1}&\begin{bmatrix}    
\lambda_2&\cdots&\bigstar\\\    
&\ddots&\bigstar\\\    
&&\lambda_n    
\end{bmatrix}_{n-1}\end{bmatrix}$     
    
 $=\begin{bmatrix}    
\lambda_1&\cdots&\bigstar\\\    
&\ddots&\bigstar\\\    
&&\lambda_n    
\end{bmatrix}$     
    
 $\Rightarrow (PR)^{-1}\cdot A\cdot(PR)=\begin{bmatrix}    
\lambda_1&\cdots&\bigstar\\\    
&\ddots&\bigstar\\\    
&&\lambda_n    
\end{bmatrix}$     
